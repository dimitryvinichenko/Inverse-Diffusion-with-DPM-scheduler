{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "17c6be2d-f674-4df0-bd96-92552eab55a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "import sys\n",
    "import ast\n",
    "import torch\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "\n",
    "sys.path.append(\"/media/alexander/SSD990PRO/sk_harmonization/FastSAM/\")\n",
    "\n",
    "from fastsam import FastSAM, FastSAMPrompt \n",
    "from utils.tools import convert_box_xywh_to_xyxy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "027fcd8e-1834-468c-9be9-bb3cf7d62d1d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/media/alexander/SSD990PRO/sk_harmonization/FastSAM/ultralytics/nn/tasks.py:518: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  return torch.load(file, map_location='cpu'), file  # load\n"
     ]
    }
   ],
   "source": [
    "model_path = \"/media/alexander/SSD990PRO/sk_harmonization/FastSAM/weights/FastSAM-x.pt\"\n",
    "model = FastSAM(model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d1875a44-0347-4725-9f87-75b3c02ded40",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Args: \n",
    "    def __init__(self, ):\n",
    "        self.imgsz = 1024  # image size\n",
    "        self.iou = 0.9  # iou threshold for filtering the annotations\n",
    "        self.conf = 0.4  # object confidence threshold\n",
    "        self.text_prompt = None\n",
    "        self.output = \"./FastSAM/output/\"\n",
    "        self.randomcolor = False\n",
    "        self.point_prompt = \"[[0,0]]\"  # [[x1,y1],[x2,y2]]\n",
    "        self.point_label = \"[0]\"  #[ 1,0] 0:background, 1:foreground\n",
    "        self.box_prompt = \"[[0,0,0,0]]\"  # [[x,y,w,h],[x2,y2,w2,h2]] support multiple boxes\n",
    "        self.better_quality = True   # \"better quality using morphologyEx\",\n",
    "        self.device = \"cuda:0\"\n",
    "        self.retina = True  # draw high-resolution segmentation masks\n",
    "        self.withContours = False  # draw edges\n",
    "\n",
    "\n",
    "def main(args, img_path):\n",
    "    args.point_prompt = ast.literal_eval(args.point_prompt)\n",
    "    args.box_prompt = convert_box_xywh_to_xyxy(ast.literal_eval(args.box_prompt))\n",
    "    args.point_label = ast.literal_eval(args.point_label)\n",
    "    input = Image.open(img_path)\n",
    "    input = input.convert(\"RGB\")\n",
    "    everything_results = model(\n",
    "        input,\n",
    "        device=args.device,\n",
    "        retina_masks=args.retina,\n",
    "        imgsz=args.imgsz,\n",
    "        conf=args.conf,\n",
    "        iou=args.iou    \n",
    "        )\n",
    "    bboxes = None\n",
    "    points = None\n",
    "    point_label = None\n",
    "    prompt_process = FastSAMPrompt(input, everything_results, device=args.device)\n",
    "    if args.box_prompt[0][2] != 0 and args.box_prompt[0][3] != 0:\n",
    "            ann = prompt_process.box_prompt(bboxes=args.box_prompt)\n",
    "            bboxes = args.box_prompt\n",
    "    elif args.text_prompt != None:\n",
    "        ann = prompt_process.text_prompt(text=args.text_prompt)\n",
    "    elif args.point_prompt[0] != [0, 0]:\n",
    "        ann = prompt_process.point_prompt(\n",
    "            points=args.point_prompt, pointlabel=args.point_label\n",
    "        )\n",
    "        points = args.point_prompt\n",
    "        point_label = args.point_label\n",
    "    else:\n",
    "        ann = prompt_process.everything_prompt()\n",
    "    prompt_process.plot(\n",
    "        annotations=ann,\n",
    "        output_path=args.output+img_path.split(\"/\")[-1],\n",
    "        bboxes = bboxes,\n",
    "        points = points,\n",
    "        point_label = point_label,\n",
    "        withContours=args.withContours,\n",
    "        better_quality=args.better_quality,\n",
    "    )\n",
    "    return args.output+img_path.split(\"/\")[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1922,
   "id": "f49ac168-35e6-40ab-9251-4cb395865a6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "n=22"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcbee9d1-9005-4eab-9732-0626f57ac7b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# im_path = \"./FastSAM/images/dogs.jpg\"\n",
    "im_path = \"/media/alexander/DATA/dima_vinichenko/data/sd_15/DDIM/\" + str(n) + \".png\"\n",
    "# im_path = \"./data/imgs/pink_suit.png\"\n",
    "\n",
    "args = Args()\n",
    "args.text_prompt = \"\"\n",
    "# args.text_prompt = \"a pink suit\"\n",
    "args.iou = 0.9\n",
    "args.conf = 0.4\n",
    "args.withContours = True\n",
    "# args.point_label = \"[1]\"\n",
    "# args.point_prompt = \"[[512, 512]]\"\n",
    "out_path = main(args, im_path)\n",
    "Image.open(out_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df51e883-5b0f-44ff-b680-83457cbd2303",
   "metadata": {},
   "outputs": [],
   "source": [
    "everything_results = model(\n",
    "        Image.open(im_path).convert('RGB'),\n",
    "        device=args.device,\n",
    "        retina_masks=args.retina,\n",
    "        imgsz=args.imgsz,\n",
    "        conf=args.conf,\n",
    "        iou=args.iou\n",
    "     )\n",
    "\n",
    "\n",
    "mask_array_1 = everything_results[0].masks.data.cpu().numpy()[1, : ,:] \n",
    "plt.imshow(mask_array_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1886,
   "id": "ae9018b1-f498-406e-87c5-da76f0bee162",
   "metadata": {},
   "outputs": [],
   "source": [
    "# mask_array_1[mask_array_1 > 1] = 1\n",
    "# plt.imshow(mask_array_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ae070bf-68dc-4766-9a6f-145ea8ac8c5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# im_path = \"./FastSAM/images/dogs.jpg\"\n",
    "im_path = \"/media/alexander/DATA/dima_vinichenko/data/sd_15/DDPM_original/\" + str(n) + \".png\"\n",
    "# im_path = \"./data/imgs/pink_suit.png\"\n",
    "\n",
    "args = Args()\n",
    "args.text_prompt = \"\"\n",
    "# args.text_prompt = \"a pink suit\"\n",
    "args.iou = 0.9\n",
    "args.conf = 0.4\n",
    "args.withContours = True\n",
    "# args.point_label = \"[1]\"\n",
    "# args.point_prompt = \"[[512, 512]]\"\n",
    "out_path = main(args, im_path)\n",
    "Image.open(out_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f5d770c-c9cc-47c3-bddb-2a8ef0bf897e",
   "metadata": {},
   "outputs": [],
   "source": [
    "everything_results = model(\n",
    "        Image.open(im_path).convert('RGB'),\n",
    "        device=args.device,\n",
    "        retina_masks=args.retina,\n",
    "        imgsz=args.imgsz,\n",
    "        conf=args.conf,\n",
    "        iou=args.iou\n",
    "        )\n",
    "\n",
    "\n",
    "mask_array_2 = everything_results[0].masks.data.cpu().numpy()[3, : ,:] \n",
    "plt.imshow(mask_array_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d9d4d54-a239-4ed3-8593-62a63846a080",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# im_path = \"./FastSAM/images/dogs.jpg\"\n",
    "im_path = \"/media/alexander/DATA/dima_vinichenko/data/sd_15/DPM/\" + str(n) + \".png\"\n",
    "# im_path = \"./data/imgs/pink_suit.png\"\n",
    "\n",
    "args = Args()\n",
    "args.text_prompt = \"\"\n",
    "# args.text_prompt = \"a pink suit\"\n",
    "args.iou = 0.9\n",
    "args.conf = 0.4\n",
    "args.withContours = True\n",
    "# args.point_label = \"[1]\"\n",
    "# args.point_prompt = \"[[512, 512]]\"\n",
    "out_path = main(args, im_path)\n",
    "Image.open(out_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18a0f88a-2212-4c91-ba67-f8a45958d9f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "everything_results = model(\n",
    "        Image.open(im_path).convert('RGB'),\n",
    "        device=args.device,\n",
    "        retina_masks=args.retina,\n",
    "        imgsz=args.imgsz,\n",
    "        conf=args.conf,\n",
    "        iou=args.iou\n",
    "        )\n",
    "\n",
    "mask_array_3 = everything_results[0].masks.data.cpu().numpy()[1, : ,:] \n",
    "plt.imshow(mask_array_3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1955,
   "id": "e6b8da52-a1a1-46fc-9506-10322fb2d0d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# mask_array_3[mask_array_3 > 1] = 1\n",
    "# plt.imshow(mask_array_3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1956,
   "id": "2a9db3ac-5f88-4337-abf3-b9b3bdf6bfa6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# mask_array_3[mask_array_3 == 2] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d42706e5-b8ec-463e-8bdd-c0dccc3b2633",
   "metadata": {},
   "outputs": [],
   "source": [
    "# im_path = \"./FastSAM/images/dogs.jpg\"\n",
    "im_path = \"/media/alexander/DATA/dima_vinichenko/data/sd_15/DPM_AYS/\" + str(n) + \".png\"\n",
    "# im_path = \"./data/imgs/pink_suit.png\"\n",
    "\n",
    "args = Args()\n",
    "args.text_prompt = \"\"\n",
    "# args.text_prompt = \"a pink suit\"\n",
    "args.iou = 0.9\n",
    "args.conf = 0.4\n",
    "args.withContours = True\n",
    "# args.point_label = \"[1]\"\n",
    "# args.point_prompt = \"[[512, 512]]\"\n",
    "out_path = main(args, im_path)\n",
    "Image.open(out_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49e2d9ba-18e1-485b-abd5-7deb608fc21e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "everything_results = model(\n",
    "        Image.open(im_path).convert('RGB'),\n",
    "        device=args.device,\n",
    "        retina_masks=args.retina,\n",
    "        imgsz=args.imgsz,\n",
    "        conf=args.conf,\n",
    "        iou=args.iou\n",
    "        )\n",
    "\n",
    "mask_array_4 = everything_results[0].masks.data.cpu().numpy()[3, : ,:]\n",
    "plt.imshow(mask_array_4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1963,
   "id": "36ca244b-faf4-418b-b1a8-584e4aea048b",
   "metadata": {},
   "outputs": [],
   "source": [
    "mask_array = mask_array_1.astype('bool') + mask_array_2.astype('bool') + mask_array_3.astype('bool') + mask_array_4.astype('bool')\n",
    "mask_array = mask_array.astype('int')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1964,
   "id": "fe546829-0103-4dc3-bff4-ca3521e90923",
   "metadata": {},
   "outputs": [],
   "source": [
    "mask_array_back = 1 - mask_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1965,
   "id": "f982f7ec-c018-44d4-a8d6-7c37da058ca3",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "image_tmp = np.array(Image.open(im_path))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1966,
   "id": "370c234d-9493-449f-9350-8ef985521f8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(3):\n",
    "    image_tmp[:,:,i] = np.multiply(image_tmp[:,:,i], mask_array_back)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33808762-679d-4c58-8d3d-1fcb4afe03a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "img = Image.fromarray(image_tmp, 'RGB') \n",
    "img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1968,
   "id": "80d3d501-d130-4cd4-924b-2928c12636b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "path = \"/media/alexander/DATA/dima_vinichenko/data/sd_15/mask/\"\n",
    "np.save(path  + str(n), mask_array_back)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "research",
   "language": "python",
   "name": "research"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
