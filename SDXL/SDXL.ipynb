{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08367fa6-c0d2-4711-b1b7-cfa2c7a407f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "\n",
    "# Пути к папкам\n",
    "base_dir = '/media/alexander/DATA/dima_vinichenko/data/SDXL'\n",
    "folders = ['DDIM', 'DPM', 'DPM_AYS', 'DDPM_original']\n",
    "\n",
    "# Настройки сетки\n",
    "num_images = 22\n",
    "num_cols = len(folders)\n",
    "num_rows = num_images\n",
    "\n",
    "# Размер фигуры\n",
    "figsize_per_image = 2  # Размер изображения в дюймах\n",
    "fig, axes = plt.subplots(num_rows, num_cols, figsize=(figsize_per_image*num_cols, figsize_per_image*num_rows))\n",
    "\n",
    "# Загружаем и отображаем изображения\n",
    "for row in range(num_rows):\n",
    "    image_idx = row + 1\n",
    "    for col, folder in enumerate(folders):\n",
    "        image_path = os.path.join(base_dir, folder, f\"{image_idx}.png\")\n",
    "        if os.path.exists(image_path):\n",
    "            img = Image.open(image_path)\n",
    "            axes[row, col].imshow(img)\n",
    "        axes[row, col].axis('off')\n",
    "\n",
    "# Добавляем заголовки к столбцам\n",
    "for col, folder in enumerate(folders):\n",
    "    axes[0, col].set_title(folder, fontsize=10)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7a7b5a15-6569-4d14-8935-d7f710d77515",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "\n",
    "from diffusers import StableDiffusionXLPipeline\n",
    "from diffusers.utils import make_image_grid\n",
    "\n",
    "from IPython.display import display\n",
    "\n",
    "from diffusers import DPMSolverMultistepScheduler as DefaultDPMSolver\n",
    "\n",
    "# Add support for setting custom timesteps\n",
    "class DPMSolverMultistepScheduler(DefaultDPMSolver):\n",
    "    def set_timesteps(\n",
    "        self, num_inference_steps=None, device=None,\n",
    "        timesteps=None\n",
    "    ):\n",
    "        if timesteps is None:\n",
    "            super().set_timesteps(num_inference_steps, device)\n",
    "            return\n",
    "\n",
    "        all_sigmas = np.array(((1 - self.alphas_cumprod) / self.alphas_cumprod) ** 0.5)\n",
    "        self.sigmas = torch.from_numpy(all_sigmas[timesteps])\n",
    "        self.timesteps = torch.tensor(timesteps[:-1]).to(device=device, dtype=torch.int64) # Ignore the last 0\n",
    "\n",
    "        self.num_inference_steps = len(timesteps)\n",
    "\n",
    "        self.model_outputs = [\n",
    "            None,\n",
    "        ] * self.config.solver_order\n",
    "        self.lower_order_nums = 0\n",
    "\n",
    "        # add an index counter for schedulers that allow duplicated timesteps\n",
    "        self._step_index = None\n",
    "        self._begin_index = None\n",
    "        self.sigmas = self.sigmas.to(\"cpu\")  # to avoid too much CPU/GPU communication\n",
    "\n",
    "\n",
    "from diffusers import DPMSolverMultistepInverseScheduler as DefaultDPMSolverInverse\n",
    "\n",
    "class DPMSolverMultistepInverseScheduler(DefaultDPMSolverInverse):\n",
    "    \n",
    "    def set_timesteps(\n",
    "        self, num_inference_steps=None, device=None,\n",
    "        timesteps=None\n",
    "    ):\n",
    "        if timesteps is None:\n",
    "            super().set_timesteps(num_inference_steps, device)\n",
    "            return\n",
    "\n",
    "        all_sigmas = np.array(((1 - self.alphas_cumprod) / self.alphas_cumprod) ** 0.5)\n",
    "        self.sigmas = torch.from_numpy(all_sigmas[timesteps])\n",
    "        self.timesteps = torch.tensor(timesteps[:-1]).to(device=device, dtype=torch.int64) # Ignore the last 0\n",
    "\n",
    "        self.num_inference_steps = len(timesteps)\n",
    "\n",
    "        self.model_outputs = [\n",
    "            None,\n",
    "        ] * self.config.solver_order\n",
    "        self.lower_order_nums = 0\n",
    "\n",
    "        # add an index counter for schedulers that allow duplicated timesteps\n",
    "        self._step_index = None\n",
    "        self._begin_index = None\n",
    "        self.sigmas = self.sigmas.to(\"cpu\")  # to avoid too much CPU/GPU communication\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c09bfea5-1166-4ad4-82e8-6c35f99809be",
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "from diffusers import DDIMInverseScheduler\n",
    "from torchvision import transforms as tvt\n",
    "from diffusers.utils import make_image_grid\n",
    "import torch\n",
    "\n",
    "from diffusers import DDIMScheduler\n",
    "\n",
    "@torch.no_grad()\n",
    "def ddim_inversion(input_image, num_steps):\n",
    "    \n",
    "    # dtype = torch.float16\n",
    "    \n",
    "    pipe = StableDiffusionXLPipeline.from_single_file(\n",
    "        \"/media/alexander/DATA/ai1_models/models_SDXL/sd_xl_base_1.0.safetensors\",\n",
    "        torch_dtype=torch.float16, \n",
    "        # variant=\"fp16\", \n",
    "        use_safetensors=True,\n",
    "        add_watermarker=False\n",
    "    ).to(device)\n",
    "\n",
    "    # pipe.scheduler = DDIMScheduler.from_config(pipe.scheduler.config)\n",
    "    inverse_scheduler = DDIMInverseScheduler.from_config(pipe.scheduler.config)\n",
    "    pipe.scheduler = inverse_scheduler\n",
    "    \n",
    "    pipe.to(device)\n",
    "    \n",
    "    dtype = torch.float32\n",
    "    seed=10\n",
    "    generator = torch.Generator(device).manual_seed(seed)\n",
    "    \n",
    "    input_image = tvt.ToTensor()(input_image)[None, ...]\n",
    "    input_image = input_image.to(device=device, dtype=dtype)\n",
    "    \n",
    "    vae = pipe.vae\n",
    "    vae.to(device, dtype=dtype)\n",
    "        \n",
    "    latents_mean = latents_std = None\n",
    "    if hasattr(vae.config, \"latents_mean\") and vae.config.latents_mean is not None:\n",
    "        latents_mean = torch.tensor(vae.config.latents_mean).view(1, 4, 1, 1)\n",
    "    if hasattr(vae.config, \"latents_std\") and vae.config.latents_std is not None:\n",
    "        latents_std = torch.tensor(vae.config.latents_std).view(1, 4, 1, 1)\n",
    "    \n",
    "    init_latents = vae.encode(input_image * 2 - 1).latent_dist.sample(generator)\n",
    "    # init_latents = vae.encode(input_image).latent_dist.sample(generator)\n",
    "    \n",
    "    if latents_mean is not None and latents_std is not None:\n",
    "        latents_mean = latents_mean.to(device=device, dtype=dtype)\n",
    "        latents_std = latents_std.to(device=device, dtype=dtype)\n",
    "        init_latents = (init_latents - latents_mean) * vae.config.scaling_factor / latents_std\n",
    "    else:\n",
    "\n",
    "        init_latents = init_latents * vae.config.scaling_factor \n",
    "\n",
    "    latents = init_latents\n",
    "    latents = latents.type(torch.float16)\n",
    "    print('latents', latents.shape)\n",
    "    # inverse_scheduler = DDIMInverseScheduler.from_config(pipe.scheduler.config)\n",
    "    # pipe.scheduler = inverse_scheduler\n",
    "\n",
    "    inv_latents = pipe(prompt=\"\", negative_prompt=\"\", guidance_scale=1.,\n",
    "                          width=input_image.shape[-1], height=input_image.shape[-2],\n",
    "                          output_type='latent', return_dict=False,\n",
    "                          num_inference_steps=num_steps, latents=latents)\n",
    "\n",
    "        \n",
    "    return inv_latents\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1006edaf-e244-4fe7-959e-6a59a8f1d90d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "# from diffusers import DDIMInverseScheduler\n",
    "from torchvision import transforms as tvt\n",
    "\n",
    "\n",
    "@torch.no_grad()\n",
    "def dpm_inversion(input_image, num_steps, timesteps):\n",
    "    \n",
    "    # dtype = torch.float16\n",
    "    \n",
    "    pipe = StableDiffusionXLPipeline.from_single_file(\n",
    "        \"/media/alexander/DATA/ai1_models/models_SDXL/sd_xl_base_1.0.safetensors\",\n",
    "        torch_dtype=torch.float16, \n",
    "        # variant=\"fp16\", \n",
    "        use_safetensors=True,\n",
    "        add_watermarker=False\n",
    "    ).to(device)\n",
    "\n",
    "    # pipe.scheduler = DDIMScheduler.from_config(pipe.scheduler.config)\n",
    "    inverse_scheduler = DPMSolverMultistepInverseScheduler.from_config(pipe.scheduler.config)\n",
    "    pipe.scheduler = inverse_scheduler\n",
    "    \n",
    "    pipe.to(device)\n",
    "    \n",
    "    dtype = torch.float32\n",
    "    seed=10\n",
    "    generator = torch.Generator(device).manual_seed(seed)\n",
    "    \n",
    "    input_image = tvt.ToTensor()(input_image)[None, ...]\n",
    "    input_image = input_image.to(device=device, dtype=dtype)\n",
    "    \n",
    "    vae = pipe.vae\n",
    "    vae.to(device, dtype=dtype)\n",
    "        \n",
    "    latents_mean = latents_std = None\n",
    "    if hasattr(vae.config, \"latents_mean\") and vae.config.latents_mean is not None:\n",
    "        latents_mean = torch.tensor(vae.config.latents_mean).view(1, 4, 1, 1)\n",
    "    if hasattr(vae.config, \"latents_std\") and vae.config.latents_std is not None:\n",
    "        latents_std = torch.tensor(vae.config.latents_std).view(1, 4, 1, 1)\n",
    "    \n",
    "    init_latents = vae.encode(input_image * 2 - 1).latent_dist.sample(generator)\n",
    "    # init_latents = vae.encode(input_image).latent_dist.sample(generator)\n",
    "    \n",
    "    if latents_mean is not None and latents_std is not None:\n",
    "        latents_mean = latents_mean.to(device=device, dtype=dtype)\n",
    "        latents_std = latents_std.to(device=device, dtype=dtype)\n",
    "        init_latents = (init_latents - latents_mean) * vae.config.scaling_factor / latents_std\n",
    "    else:\n",
    "\n",
    "        init_latents = init_latents * vae.config.scaling_factor \n",
    "\n",
    "    latents = init_latents\n",
    "    latents = latents.type(torch.float16)\n",
    "    print('latents', latents.shape)\n",
    "    # inverse_scheduler = DDIMInverseScheduler.from_config(pipe.scheduler.config)\n",
    "    # pipe.scheduler = inverse_scheduler\n",
    "\n",
    "    inv_latents = pipe(prompt=\"\", negative_prompt=\"\", guidance_scale=1.,\n",
    "                          width=input_image.shape[-1], height=input_image.shape[-2],\n",
    "                          output_type='latent', return_dict=False,\n",
    "                          num_inference_steps=num_steps, latents=latents,\n",
    "                          timesteps=timesteps\n",
    "                      )\n",
    "\n",
    "        \n",
    "    return inv_latents\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "94fcb903-7b9e-423a-a513-89e3f9310ab9",
   "metadata": {},
   "outputs": [],
   "source": [
    "sampling_schedule = [999, 845, 730, 587, 443, 310, 193, 116, 53, 13, 0]\n",
    "prompt_list = []\n",
    "edit_prompt_list = []"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba16b876-c8d0-4775-8b49-ec72e2f5d06e",
   "metadata": {},
   "source": [
    "генерирую изображение с DDPM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 765,
   "id": "ea9b6d94-dea7-4d85-8cb8-95670e63bf77",
   "metadata": {},
   "outputs": [],
   "source": [
    "orig_prompts = [\n",
    "    'Photo of a golden retriever in the park',\n",
    "    'Photo of a horse running on the beach',\n",
    "    'Realistic photo of a cat on the sofa',\n",
    "    'Photo of a tiger in the jungle',\n",
    "    'Realistic photo of a rabbit in the garden',\n",
    "    'Photo of a dog sleeping on a blanket',\n",
    "    'Photo of a giraffe in the savannah',\n",
    "    'Photo of a fox in the snowy field',\n",
    "    'Photo of a zebra drinking from a lake',\n",
    "    'Photo of a woman sitting in a cafe',\n",
    "    'Realistic photo of a basketball on the court',\n",
    "    'Realistic photo of a guitar on a wooden floor',\n",
    "    'Photo of a man surfing on the ocean',\n",
    "    'Realistic photo of a boy holding an ice cream',\n",
    "    'Photo of a plane flying over the mountains',\n",
    "    'Photo of a cat sleeping on a bed',\n",
    "    'Photo of a lion resting on a rock',\n",
    "    'Photo of a leopard in the jungle',\n",
    "    'Realistic photo of a white dove in the sky',\n",
    "    'Photo of a camel in the desert',\n",
    "    'Photo of a cyclist riding on a mountain trail',\n",
    "    'Photo of a sailboat on the ocean at sunset',\n",
    "    'Realistic photo of a child playing with a kite',\n",
    "    'Realistic photo of a woman holding a bouquet',\n",
    "    'Photo of a black car on a city street',\n",
    "    'Photo of a pizza on a wooden table',\n",
    "    'Photo of a black dog on the snow',\n",
    "    'Realistic photo of a firefighter in uniform',\n",
    "    'Photo of a red rose in a garden',\n",
    "    'Photo of a deer standing in a forest clearing',\n",
    "    'Photo of a skier on a snowy mountain',\n",
    "    'Photo of a man fishing by a river',\n",
    "    'Photo of a yellow taxi in New York City',\n",
    "    'Photo of a violin on a concert stage',\n",
    "    'Photo of a shark swimming in the ocean',\n",
    "    'Photo of a ballerina dancing in a studio',\n",
    "    'Photo of a penguin on ice',\n",
    "    'Photo of a raccoon in a tree',\n",
    "    'Photo of a monkey sitting on a rock',\n",
    "    'Realistic photo of goat on a cliff'\n",
    "]\n",
    "\n",
    "edit_prompts = [\n",
    "    'Photo of a beagle in the park',\n",
    "    'Photo of a camel running on the beach',\n",
    "    'Realistic photo of a dog on the sofa',\n",
    "    'Photo of a leopard in the jungle',\n",
    "    'Realistic photo of a squirrel in the garden',\n",
    "    'Photo of a cat sleeping on a blanket',\n",
    "    'Photo of an elephant in the savannah',\n",
    "    'Photo of a deer in the snowy field',\n",
    "    'Photo of a gazelle drinking from a lake',\n",
    "    'Photo of a man sitting in a cafe',\n",
    "    'Realistic photo of a football on the court',\n",
    "    'Realistic photo of a violin on a wooden floor',\n",
    "    'Photo of a woman surfing on the ocean',\n",
    "    'Realistic photo of a girl holding an ice cream',\n",
    "    'Photo of a helicopter flying over the mountains',\n",
    "    'Photo of a dog sleeping on a bed',\n",
    "    'Photo of a cheetah resting on a rock',\n",
    "    'Photo of a panther in the jungle',\n",
    "    'Realistic photo of a black dove in the sky',\n",
    "    'Photo of a llama in the desert',\n",
    "    'Photo of a hiker riding on a mountain trail',\n",
    "    'Photo of a yacht on the ocean at sunset',\n",
    "    'Realistic photo of a boy playing with a kite',\n",
    "    'Realistic photo of a man holding a bouquet',\n",
    "    'Photo of a white car on a city street',\n",
    "    'Photo of a burger on a wooden table',\n",
    "    'Photo of a golden retriever on the snow',\n",
    "    'Realistic photo of a police officer in uniform',\n",
    "    'Photo of a sunflower in a garden',\n",
    "    'Photo of a moose standing in a forest clearing',\n",
    "    'Photo of a snowboarder on a snowy mountain',\n",
    "    'Photo of a woman fishing by a river',\n",
    "    'Photo of a blue taxi in New York City',\n",
    "    'Photo of a cello on a concert stage',\n",
    "    'Photo of a whale swimming in the ocean',\n",
    "    'Photo of a gymnast dancing in a studio',\n",
    "    'Photo of a seal on ice',\n",
    "    'Photo of an owl in a tree',\n",
    "    'Photo of a baboon sitting on a rock',\n",
    "    'Realistic photo of ibex on a cliff'\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 766,
   "id": "858f9a1e-1ab7-463c-91e0-75863b290623",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6e2b15b1b7be4eea839cb738007024bc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading pipeline components...:   0%|          | 0/7 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint were not used when initializing CLIPTextModel: \n",
      " ['text_model.embeddings.position_ids']\n"
     ]
    }
   ],
   "source": [
    "from src.sdxl_pipeline import StableDiffusionXLPipeline\n",
    "from src.utils import plot_image_grid, print_images\n",
    "\n",
    "import torch\n",
    "from diffusers import DDPMScheduler\n",
    "\n",
    "\n",
    "device = torch.device(\"mps\" if torch.backends.mps.is_available() else \"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "pipe = StableDiffusionXLPipeline.from_single_file(\n",
    "    \"/media/alexander/DATA/ai1_models/models_SDXL/sd_xl_base_1.0.safetensors\",\n",
    "    torch_dtype=torch.float16, \n",
    "    # variant=\"fp16\", \n",
    "    use_safetensors=True,\n",
    "    add_watermarker=False,\n",
    ").to(device)\n",
    "\n",
    "pipe.scheduler = DDPMScheduler.from_config(pipe.scheduler.config)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 767,
   "id": "00e16397-599d-41c6-98d9-d29b933d4e5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "i = 22"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e87665e8-71da-426b-bce4-5f0a87afa14a",
   "metadata": {},
   "source": [
    "Generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 768,
   "id": "da88c6f7-fab4-4016-8353-65ab8aa6e841",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Realistic photo of goat on a cliff\n",
      "Realistic photo of ibex on a cliff\n"
     ]
    }
   ],
   "source": [
    "tmp = 39\n",
    "\n",
    "prompt = orig_prompts[tmp]\n",
    "print(prompt)\n",
    "\n",
    "prompt_ = edit_prompts[tmp]\n",
    "print(prompt_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 783,
   "id": "34fa6f82-c0e7-4383-bc7d-f1af312547d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_steps = 50\n",
    "\n",
    "# seed = None\n",
    "# latents, seed = pipe.get_latents(seed=seed, device=device)\n",
    "image = pipe(prompt=prompt, negative_prompt=\"\", guidance_scale=7.5,\n",
    "             num_inference_steps=num_steps).images[0]\n",
    "\n",
    "\n",
    "image\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 784,
   "id": "7e761441-3481-4210-84ec-9718d25b63f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "path = '/media/alexander/DATA/dima_vinichenko'\n",
    "image_path = path + '/data/SDXL/DDPM_original'\n",
    "\n",
    "image.save(f\"{image_path}/{i}.png\")\n",
    "im = Image.open(image_path + f\"/{i}.png\")\n",
    "im"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a36b7cab-c664-4354-9abb-c24436b613d9",
   "metadata": {},
   "source": [
    "DPM++ AYS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 785,
   "id": "55e5128c-8f40-442f-bcc7-8c7b9808a437",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_steps = 10\n",
    "\n",
    "\n",
    "inv_latents = dpm_inversion(image, num_steps=num_steps, timesteps = sampling_schedule[::-1])\n",
    "\n",
    "# pipe = StableDiffusionXLPipeline.from_single_file(\n",
    "#     \"/media/alexander/DATA/ai1_models/models_SDXL/sd_xl_base_1.0.safetensors\",\n",
    "#     torch_dtype=torch.float16, \n",
    "#     # variant=\"fp16\", \n",
    "#     use_safetensors=True,\n",
    "#     add_watermarker=False\n",
    "# ).to(device)\n",
    "\n",
    "pipe.scheduler = DPMSolverMultistepScheduler.from_config(pipe.scheduler.config)\n",
    "\n",
    "image_ = pipe(prompt=prompt_, negative_prompt=\"\", guidance_scale=7.5,\n",
    "             num_inference_steps=num_steps, latents=inv_latents[0], timesteps=sampling_schedule).images[0]\n",
    "\n",
    "\n",
    "display(make_image_grid([image, image_], rows=1, cols=2))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 786,
   "id": "f2c53ad4-a659-47e7-83f9-91f4dc27d37b",
   "metadata": {},
   "outputs": [],
   "source": [
    "path = '/media/alexander/DATA/dima_vinichenko'\n",
    "image_path = path + '/data/SDXL/DPM_AYS'\n",
    "\n",
    "image_.save(f\"{image_path}/{i}.png\")\n",
    "im = Image.open(image_path + f\"/{i}.png\")\n",
    "im\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b2fec43-432b-4e8d-9a36-b6f71ac631a0",
   "metadata": {},
   "source": [
    "DPM++"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 787,
   "id": "415e45e2-0c81-4533-ae90-ec3828b324c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_steps = 10\n",
    "\n",
    "inv_latents = dpm_inversion(image, num_steps=num_steps, timesteps = None)\n",
    "\n",
    "# pipe = StableDiffusionXLPipeline.from_single_file(\n",
    "#     \"/media/alexander/DATA/ai1_models/models_SDXL/sd_xl_base_1.0.safetensors\",\n",
    "#     torch_dtype=torch.float16, \n",
    "#     # variant=\"fp16\", \n",
    "#     use_safetensors=True,\n",
    "#     add_watermarker=False\n",
    "# ).to(device)\n",
    "\n",
    "pipe.scheduler = DPMSolverMultistepScheduler.from_config(pipe.scheduler.config)\n",
    "\n",
    "# prompt_ = 'Realistic photography of a cat on the snow'\n",
    "\n",
    "image_ = pipe(prompt=prompt_, negative_prompt=\"\", guidance_scale=7.5,\n",
    "             num_inference_steps=num_steps, latents=inv_latents[0], timesteps=None).images[0]\n",
    "\n",
    "display(make_image_grid([image, image_], rows=1, cols=2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad238232-0fc1-4f4c-be31-ba65255c1005",
   "metadata": {},
   "outputs": [],
   "source": [
    "path = '/media/alexander/DATA/dima_vinichenko'\n",
    "image_path = path + '/data/SDXL/DPM'\n",
    "\n",
    "\n",
    "\n",
    "image_.save(f\"{image_path}/{i}.png\")\n",
    "im = Image.open(image_path + f\"/{i}.png\")\n",
    "im"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df1dbf73-04ad-49f7-922e-0db86aaed90c",
   "metadata": {},
   "source": [
    "DDIM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04803a6e-2276-4751-93f9-abc6acf7d4b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_steps = 10\n",
    "\n",
    "inv_latents = ddim_inversion(image, num_steps=num_steps)\n",
    "\n",
    "# pipe = StableDiffusionXLPipeline.from_single_file(\n",
    "#     \"/media/alexander/DATA/ai1_models/models_SDXL/sd_xl_base_1.0.safetensors\",\n",
    "#     torch_dtype=torch.float16, \n",
    "#     # variant=\"fp16\", \n",
    "#     use_safetensors=True,\n",
    "#     add_watermarker=False\n",
    "# ).to(device)\n",
    "\n",
    "pipe.scheduler = DDIMScheduler.from_config(pipe.scheduler.config)\n",
    "\n",
    "# prompt_ = 'Realistic photography of a cat on the snow'\n",
    "\n",
    "image_ = pipe(prompt=prompt_, negative_prompt=\"\", guidance_scale=7.5,\n",
    "             num_inference_steps=num_steps, latents=inv_latents[0]).images[0]\n",
    "\n",
    "display(make_image_grid([image, image_], rows=1, cols=2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c79a0b41-4410-4cd3-9ee1-89d6fb312673",
   "metadata": {},
   "outputs": [],
   "source": [
    "path = '/media/alexander/DATA/dima_vinichenko'\n",
    "image_path = path + '/data/SDXL/DDIM'\n",
    "\n",
    "image_.save(f\"{image_path}/{i}.png\")\n",
    "im = Image.open(image_path + f'/{i}.png')\n",
    "im"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 780,
   "id": "2c6c31b6-360a-4ac1-9f8b-dc5d65245957",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import gc\n",
    "\n",
    "del pipe\n",
    "gc.collect()\n",
    "torch.cuda.empty_cache()\n",
    "torch.cuda.ipc_collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 781,
   "id": "f3e94981-454a-4be0-8da4-12ae1b10b034",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Beautiful DSLR Photograph of a penguin on the beach, golden hour',\n",
       " 'Realistic photography of a dog on the snow',\n",
       " 'realistic photo of a bear on the rock',\n",
       " 'photo of a puppy on the grass',\n",
       " 'photo of a yellow car in the city',\n",
       " 'Realistic photography of a cat in the forest',\n",
       " 'realistic photo of a wolf on the rock',\n",
       " 'realistic photo of a wolf on the beach',\n",
       " 'realistic photo of a wolf in the snow forest',\n",
       " 'Photo of a sailing boat on the lake',\n",
       " 'Photo of a cat on the windowsill',\n",
       " 'Photo of a white swan swimming on the river',\n",
       " 'Realistic photo of a cat on the sofa',\n",
       " 'Photo of a tiger in the jungle',\n",
       " 'Realistic photo of a rabbit in the garden',\n",
       " 'Photo of a plane flying over the mountains',\n",
       " 'Photo of a lion resting on a rock',\n",
       " 'Photo of a black car on a city street',\n",
       " 'Photo of a deer standing in a forest clearing',\n",
       " 'Photo of a penguin on ice',\n",
       " 'Photo of a raccoon in a tree',\n",
       " 'Realistic photo of goat on a cliff']"
      ]
     },
     "execution_count": 781,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prompt_list.append(prompt)\n",
    "prompt_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 782,
   "id": "d1d1d40d-2dd8-4577-8c23-db7fdf612a91",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Beautiful DSLR Photograph of a dog on the beach, golden hour',\n",
       " 'Realistic photography of a cat on the snow',\n",
       " 'realistic photo of a wolf on the rock',\n",
       " 'photo of a kitty on the grass',\n",
       " 'photo of a red car in the city',\n",
       " 'Realistic photography of a dog in the forest',\n",
       " 'realistic photo of a bear on the rock',\n",
       " 'realistic photo of a bear on the beach',\n",
       " 'realistic photo of a dog in the snow forest',\n",
       " 'Photo of a motorboat on the lake',\n",
       " 'Photo of a dog on the windowsill',\n",
       " 'Photo of a black swan swimming on the river',\n",
       " 'Realistic photo of a dog on the sofa',\n",
       " 'Photo of a leopard in the jungle',\n",
       " 'Realistic photo of a squirrel in the garden',\n",
       " 'Photo of a helicopter flying over the mountains',\n",
       " 'Photo of a cheetah resting on a rock',\n",
       " 'Photo of a white car on a city street',\n",
       " 'Photo of a moose standing in a forest clearing',\n",
       " 'Photo of a seal on ice',\n",
       " 'Photo of an owl in a tree',\n",
       " 'Realistic photo of ibex on a cliff']"
      ]
     },
     "execution_count": 782,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "edit_prompt_list.append(prompt_)\n",
    "edit_prompt_list\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2245405-a753-4bae-86a7-4a88836a9d47",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "research",
   "language": "python",
   "name": "research"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
